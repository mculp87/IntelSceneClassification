{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy import signal as sig\n",
    "\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import imagesize\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\n",
    "import torch\n",
    "# from fastai.vision import *\n",
    "# from fastai.metrics import *\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "DBG_SEED = 2718\n",
    "np.random.seed(DBG_SEED)\n",
    "torch.cuda.manual_seed_all(DBG_SEED)\n",
    "\n",
    "from sporco import util\n",
    "from sporco import linalg\n",
    "from sporco import plot\n",
    "plot.config_notebook_plotting()\n",
    "from sporco.cupy import (cupy_enabled, np2cp, cp2np, select_device_by_load,\n",
    "                         gpu_info)\n",
    "from sporco.cupy.dictlrn import onlinecdl\n",
    "from sporco.cupy.admm import cbpdn\n",
    "from sporco.cupy import cnvrep\n",
    "from sporco.cupy import linalg as cplinalg\n",
    "from sporco.cupy.linalg import irfftn,rfftn\n",
    "from sporco.cupy.linalg import inner\n",
    "\n",
    "import torch as pt\n",
    "print(torch.cuda.is_available())\n",
    "import torchvision as tv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NoiseProfile:\n",
    "    def __init__(self, seed=None, shape=None, dtype=np.float32):\n",
    "        self.seed = seed\n",
    "        self.shape = shape\n",
    "        if seed:\n",
    "            np.random.seed(seed)\n",
    "        if shape:\n",
    "            self.epsilon = self.sample(shape=shape, dtype=dtype)\n",
    "        else:\n",
    "            self.epsilon = None\n",
    "        \n",
    "    def sample(self, shape=None):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def transform(self, X, idx, out=None):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class AdditiveWhiteNoise(NoiseProfile):\n",
    "    def sample(self, shape, dtype=np.float32):\n",
    "        self.epsilon = np.random.normal(self.mean, self.std, shape).astype(dtype)\n",
    "        return self.epsilon\n",
    "    \n",
    "    def transform(self, X, idx, out=None):\n",
    "        return np.add(X, self.epsilon[idx,...], out=out)\n",
    "    \n",
    "    def __init__(self, mean, std, shape=None, seed=None, dtype=np.float32):\n",
    "        self.mean = mean\n",
    "        \n",
    "        assert 0.0 <= std, \"Standard deviation must be non-negative.\"\n",
    "        self.std = std\n",
    "        \n",
    "        super().__init__(seed=seed, shape=shape, dtype=dtype)\n",
    "\n",
    "class ScalarRayleighNoise(NoiseProfile):\n",
    "    def sample(self, shape=None, dtype=np.float32):\n",
    "        if shape:\n",
    "            self.shape = shape\n",
    "        self.epsilon = np.random.rayleigh(scale=self.scale, size=self.shape).astype(dtype)\n",
    "        return self.epsilon\n",
    "    \n",
    "    def transform(self, X, idx, out=None):\n",
    "        return np.multiply(X, self.epsilon[idx,...], out=out)\n",
    "    \n",
    "    def __init__(self, scale, shape=None, seed=None, dtype=np.float32):\n",
    "        assert 0.0 < scale, \"Rayleigh scale parameter must be positive.\"\n",
    "        self.scale = scale\n",
    "        \n",
    "        super().__init__(seed=seed, shape=shape, dtype=dtype)\n",
    "\n",
    "\n",
    "class DropoutNoise(NoiseProfile):\n",
    "    def sample(self, shape=None, dtype=np.bool):\n",
    "        if shape is not None:\n",
    "            self.shape = shape\n",
    "        self.epsilon = np.random.binomial(1, self.mean, self.shape).astype(np.bool)\n",
    "        return self.epsilon\n",
    "    \n",
    "    def transform(self, X, idx, out=None):\n",
    "        return np.multiply(X, self.epsilon[idx,...], out=out)\n",
    "    \n",
    "    def __init__(self, mean, shape=None, seed=None, dtype=np.bool):\n",
    "        assert 0.0 <= mean <= 1.0, \"The mean dropout rate must be in [0,1].\"\n",
    "        self.mean = mean\n",
    "        \n",
    "        if not isinstance(dtype, (np.bool, bool)):\n",
    "            dtype = np.bool\n",
    "            warnings.warn(\"DropoutNoise does not support non-boolean types. Non-boolean type will be ignored.\")\n",
    "        \n",
    "        super().__init__(seed=None, shape=shape, dtype=dtype)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awn = AdditiveWhiteNoise(0, 1.0, shape=(150,150,3,500))\n",
    "Z = np.random.normal(0,1,(5,5))\n",
    "dn = DropoutNoise(0.5, shape=Z.shape + (5,))\n",
    "Zd = dn.transform(Z, 0)\n",
    "# bd = np.random.binomial(1, 0.2, Z.shape).astype(np.bool)\n",
    "# Zd[bd] = 0.0\n",
    "# print(Z)\n",
    "# print(dn.epsilon[...,0])\n",
    "# print(Zd)\n",
    "# print(np.count_nonzero(Zd) / np.prod(Zd.shape))\n",
    "dn.transform(Z, 0, out=Z)\n",
    "# print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelSceneDataset(pt.utils.data.Dataset):    \n",
    "    def applyNoise(self, func):\n",
    "        return func()\n",
    "        \n",
    "    def getFolderList(self, path):\n",
    "        return [fname for fname in os.listdir(path) if os.path.isdir(os.path.join(path, fname))]\n",
    "    \n",
    "    def getFileList(self, path):\n",
    "        return [fname for fname in os.listdir(path) if os.path.isfile(os.path.join(path, fname))]\n",
    "    \n",
    "    def __init__(self, basepath, segment=\"train\", transform=None):\n",
    "        self.transform = transform\n",
    "        self.basepath = basepath\n",
    "        if segment == \"train\":\n",
    "            segpath = os.path.join(self.basepath, \"seg_train/seg_train\")\n",
    "            self.categories = self.getFolderList(segpath)\n",
    "        elif segment == \"test\":\n",
    "            segpath = os.path.join(self.basepath, \"seg_test/seg_test\")\n",
    "            self.categories = self.getFolderList(segpath)\n",
    "        labelpath = {label: os.path.join(segpath, label) for label in self.categories}\n",
    "        imgtxt = \"*.jpg\"\n",
    "        imgfnames = {label: glob.glob(os.path.join(path, \"*.jpg\")) for label,path in labelpath.items()}\n",
    "        self.fnames = [fname for cfnames in imgfnames.values() for fname in cfnames]\n",
    "        self.categories = list(imgfnames.keys())\n",
    "        \n",
    "        self.N = np.int64(sum(len(lst) for lst in imgfnames.values()))\n",
    "        self.C = np.int64(3)\n",
    "        self.imgsizes = (np.int64(150),np.int64(150)) # All images are consistent\n",
    "        self.shape = (self.N, self.C) + self.imgsizes\n",
    "        self.y = pt.zeros((self.N,), dtype=pt.int64)\n",
    "        \n",
    "        n = 0\n",
    "        c = 0\n",
    "        cumNum = 0\n",
    "        for c,fnames in tqdm(enumerate(imgfnames.values()), \"Loading Classes\"):\n",
    "            self.y[cumNum:cumNum+len(fnames)] = c\n",
    "            cumNum += len(fnames)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if pt.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        fname = self.fnames[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(Image.open(fname).convert(mode=\"RGB\"))\n",
    "        else:\n",
    "            img = Image.open(fname).convert(mode=\"RGB\")\n",
    "            \n",
    "        sample = [img, self.y[idx]]\n",
    "\n",
    "        return sample\n",
    "\n",
    "class IntelNoiseSceneDataset(IntelSceneDataset):    \n",
    "    def __init__(self,\n",
    "                 basepath,\n",
    "                 noise,\n",
    "                 segment=\"train\",\n",
    "                 transform=None):\n",
    "        super().__init__(basepath, segment, transform)\n",
    "        self.noise = noise\n",
    "        self.noise.sample(self.shape)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if pt.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        fname = self.fnames[idx]\n",
    "        \n",
    "        # Copy pil image into ndarray, scaled to [0,1] floats.\n",
    "        pilimg = Image.open(fname).convert(mode=\"RGB\").resize(self.imgsizes)\n",
    "        npimg = np.array(pilimg, dtype=np.float32).transpose((2,0,1))\n",
    "        \n",
    "        truimg = npimg.copy()\n",
    "        \n",
    "        npimg /= 255.0\n",
    "        \n",
    "        \n",
    "        # In place noise transformation of the ndarray.\n",
    "        self.noise.transform(npimg, idx, out=npimg)\n",
    "        \n",
    "        np.clip(npimg, 0, 1, out=npimg)\n",
    "        \n",
    "        \n",
    "        # Rescale to 255 intensity values.\n",
    "        npimg *= 255.0\n",
    "        \n",
    "        \n",
    "        Psig = np.linalg.norm(truimg.ravel(), ord=2)\n",
    "        Pnoise = np.linalg.norm((truimg - npimg).ravel(), ord=2)\n",
    "        SNRdB = 10.0 * np.log10(Psig / Pnoise)\n",
    "        \n",
    "        # Convert back to PIL image, cause pytorch collation hates numpy.\n",
    "        pilimg = Image.fromarray(npimg.transpose((1,2,0)).astype(np.uint8))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(pilimg)\n",
    "        else:\n",
    "            img = pilimg\n",
    "        \n",
    "        sample = [img, self.y[idx], Psig, Pnoise]\n",
    "\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose(\n",
    "    [tv.transforms.CenterCrop(150),\n",
    "     tv.transforms.ToTensor(),\n",
    "     tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = os.path.abspath(\"/mnt/hd-storage/IntelImageClassification\")\n",
    "noise = AdditiveWhiteNoise(0.0, 0.1, dtype=np.float32)\n",
    "trainNoiseDataset = IntelNoiseSceneDataset(dbpath, noise, transform=transform)\n",
    "trainNoiseDataLoader = pt.utils.data.DataLoader(trainNoiseDataset,\n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels, _, _ = iter(trainNoiseDataLoader).next()# print images\n",
    "# img = (tv.utils.make_grid(images) / 2 + 0.5).numpy().transpose((1,2,0))\n",
    "# plt.imshow(img).permute((2,3,1,0))\n",
    "# print('GroundTruth: ', ' '.join('%5s' % list(trainNoiseDataset.categories)[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = os.path.abspath(\"/mnt/hd-storage/IntelImageClassification\")\n",
    "trainDataset = IntelSceneDataset(dbpath, transform=transform)\n",
    "trainDataLoader = pt.utils.data.DataLoader(trainDataset,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J = np.random.permutation(np.arange(ds.X.shape[-1], dtype=np.int64))\n",
    "# idxTr = np.uint(0.80 * ds.X.shape[-1])\n",
    "# JTr = np.sort(J[:idxTr])\n",
    "# JTe = np.sort(J[idxTr:])\n",
    "\n",
    "# Xtnsr = torch.tensor(np.moveaxis(np.moveaxis(ds.X, source=-1, destination=0), source=-1, destination=1))\n",
    "# print(Xtnsr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 34 * 34, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # relu preserves dimensions\n",
    "        x = self.pool(F.relu(self.conv1(x))) # in R^[N, Cout, |X|-|W|+1, |X|-|W|+1]\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, np.prod(x.shape[1:]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net().to(device, non_blocking=True, dtype=pt.float32)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(trainDataLoader))\n",
    "# print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "epochs = 10\n",
    "lenDataIter = len(trainDataLoader)\n",
    "for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "    \n",
    "    trainDataIter = iter(trainDataLoader)\n",
    "    t = tqdm(enumerate(trainDataLoader, 0),\n",
    "             desc=\"[%5d] loss: %.3f\" % (0, 0.0),\n",
    "             total = lenDataIter,\n",
    "             leave=False)\n",
    "    for i,data in t:\n",
    "        inp,lbl = data[0].cuda(non_blocking=True), data[1].cuda(non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inp)\n",
    "        loss = criterion(outputs, lbl)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 100 == 0:    # print every 2000 mini-batches\n",
    "            t.set_description(\"[%5d] loss: %.3f\" %\n",
    "                  (i + 1, running_loss / 100))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.save(net, \"simple_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = pt.load(\"simple_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = IntelSceneDataset(dbpath, segment=\"train\", transform=transform)\n",
    "testDataLoader = pt.utils.data.DataLoader(testDataset,\n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "images, labels = iter(testDataLoader).next()# print images\n",
    "img = (tv.utils.make_grid(images) / 2 + 0.5).numpy().transpose((1,2,0))\n",
    "plt.imshow(img)\n",
    "print('GroundTruth: ', ' '.join('%5s' % list(testDataset.categories)[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in tqdm(enumerate(testDataLoader, 0), total=len(testDataLoader)):\n",
    "        images, labels = data[0].cuda(), data[1].cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conf = np.zeros((len(testDataset.categories),len(testDataset.categories)), dtype=np.uint)\n",
    "with torch.no_grad():\n",
    "    for i,data in tqdm(enumerate(testDataLoader, 0), total=len(testDataLoader)):\n",
    "        images, labels = data[0].cuda(), data[1].cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        for i in range(images.shape[0]):\n",
    "            Conf[labels[i], predicted[i]] += np.uint(1)\n",
    "Cprob = Conf.astype(np.float32) / np.sum(Conf, axis=0, keepdims=True).astype(np.float32)\n",
    "\n",
    "cm = metrics.ConfusionMatrixDisplay(Conf, list(testDataset.categories)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cprob = Conf.astype(np.float32) / np.sum(Conf, axis=0, keepdims=True).astype(np.float32)\n",
    "cm = metrics.ConfusionMatrixDisplay(Cprob, list(testDataset.categories)).plot()\n",
    "print(np.sum(Cprob, axis=0))\n",
    "print(np.sum(Cprob, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.style.use('default')\n",
    "cm.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformNoise = tv.transforms.Compose(\n",
    "#     [tv.transforms.ToTensor(),\n",
    "#      tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# noise = AdditiveWhiteNoise(0.0, 0.1, dtype=np.float32)\n",
    "noise = ScalarRayleighNoise(np.sqrt(2.0 / np.pi), dtype=np.float32)\n",
    "testNoiseDataset = IntelNoiseSceneDataset(dbpath, noise, segment=\"test\", transform=transform)\n",
    "# testNoiseDataset = IntelSceneDataset(dbpath, segment=\"train\", transform=transformNoise)\n",
    "testDataLoader = pt.utils.data.DataLoader(testNoiseDataset,\n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for i,data in tqdm(enumerate(testDataLoader, 0), total=len(testDataLoader)):\n",
    "#         images, labels = data[0].cuda(), data[1].cuda()\n",
    "#         outputs = net(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNoise = np.zeros((len(testNoiseDataset.categories),len(testNoiseDataset.categories)), dtype=np.uint)\n",
    "SNR = [None]*len(testDataLoader)\n",
    "with pt.no_grad():\n",
    "    for i,data in tqdm(enumerate(testDataLoader, 0), total=len(testDataLoader)):\n",
    "        images, labels, Psigs, Pnois = data[0].cuda(), data[1].cuda(), data[2], data[3]\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        SNR[i] = 10.0 * np.log10(np.array(Psigs) / np.array(Pnois))\n",
    "        for j in range(images.shape[0]):\n",
    "            CNoise[labels[j], predicted[j]] += np.uint(1)\n",
    "CNoiseprob = CNoise.astype(np.float32) / np.sum(CNoise, axis=0, keepdims=True).astype(np.float32)\n",
    "SNRNoise = np.concatenate(SNR)\n",
    "cm = metrics.ConfusionMatrixDisplay(CNoise, list(testDataset.categories)).plot()\n",
    "print(\"Accuracy is %0.4f\" % (np.sum(np.diag(CNoise)) / np.sum(CNoise)))\n",
    "print(\"Average SNR is %f\" % (np.mean(SNRNoise)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, _, _ = iter(testDataLoader).next()# print images\n",
    "img = (tv.utils.make_grid(images) / 2 + 0.5).numpy().transpose((1,2,0))\n",
    "plt.imshow(img)\n",
    "print('GroundTruth: ', ' '.join('%5s' % list(testNoiseDataset.categories)[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_dict.npy\", \"rb\") as f:\n",
    "    D = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sporco import util\n",
    "from sporco import linalg\n",
    "from sporco import plot\n",
    "plot.config_notebook_plotting()\n",
    "from sporco.cupy import (cupy_enabled, np2cp, cp2np, select_device_by_load,\n",
    "                         gpu_info)\n",
    "from sporco.cupy.dictlrn import onlinecdl\n",
    "from sporco.cupy.admm import cbpdn\n",
    "from sporco.cupy import cnvrep\n",
    "from sporco.cupy import linalg as cplinalg\n",
    "from sporco.cupy.linalg import irfftn,rfftn\n",
    "from sporco.cupy.linalg import inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npd = 16\n",
    "fltlmbd = 200.0\n",
    "lmbda = 5.0e-2\n",
    "ropt = cbpdn.ConvBPDN.Options({'Verbose': False,\n",
    "                              'DataType': np.float32,\n",
    "                              'MaxMainIter': 50,\n",
    "                              'HighMemSolve': True,\n",
    "                              'RelStopTol': 1e-7,\n",
    "                              'NonNegCoef': True,\n",
    "                              'FastSolve': True,\n",
    "                              'rho': 1e3,\n",
    "                              'AutoRho': {\"Enabled\": False}})\n",
    "CDLConf = np.zeros((len(testNoiseDataset.categories),len(testNoiseDataset.categories)), dtype=np.uint)\n",
    "t = tqdm(enumerate(testDataLoader, 0), desc=\"CDL Denoising\", total=len(testDataLoader))\n",
    "SNR = [None]*len(testDataLoader)\n",
    "for m,data in t:\n",
    "#     data = iter(testDataLoader).next()\n",
    "    X,y,Psig,_ = data\n",
    "    Xtrue = X.numpy().transpose((2,3,1,0))\n",
    "    Xl, Xh = util.tikhonov_filter(0.5*Xtrue + 0.5, fltlmbd, npd)\n",
    "    device = pt.device(\"cuda:0\" if pt.cuda.is_available() else \"cpu\")\n",
    "    X = pt.from_numpy(Xh).to(device, non_blocking=True)\n",
    "    csc = cbpdn.ConvBPDN(D, X, lmbda, ropt)\n",
    "    csc.solve()\n",
    "    Xh_recon = cp2np(csc.reconstruct())\n",
    "    X_recon_cpu = 2.0*(Xl + Xh_recon) - 1.0\n",
    "    X_recon = pt.from_numpy(X_recon_cpu.transpose((3,2,0,1))).to(device, non_blocking=True)\n",
    "    outputs = net(X_recon)\n",
    "    _, predicted = pt.max(outputs, 1)\n",
    "    Psig = np.linalg.norm(Xtrue.reshape(-1, len(y)), axis=0, ord=2)\n",
    "    Prnois = np.array(np.linalg.norm((Xtrue - X_recon_cpu).reshape(-1,len(y)), axis=0, ord=2))\n",
    "    SNR[m] = 10.0 * np.log10(Psig / Prnois)\n",
    "    for i in range(images.shape[0]):\n",
    "        CDLConf[y[i], predicted[i]] += np.uint(1)\n",
    "    \n",
    "    t.set_description(\"(Acc, SNR): (%0.4f,%f) \" % (np.sum(np.diag(CDLConf)) / np.sum(CDLConf), np.mean(SNR[m])))\n",
    "CDLSNR = np.concatenate(SNR)\n",
    "CDLCprob = CDLConf.astype(np.float32) / np.sum(CDLConf, axis=0, keepdims=True).astype(np.float32)\n",
    "print(\"Total Accuracy is %0.4f\" % (np.sum(np.diag(CDLConf)) / np.sum(CDLConf)))\n",
    "print(\"Average Reconstructed SNR %f\" % (np.mean(CDLSNR)))\n",
    "\n",
    "cm = metrics.ConfusionMatrixDisplay(CDLConf, list(testDataset.categories)).plot()\n",
    "# [d.solve() for d in tqdm(D_recon.values(), desc=\"Solving Sparse Coding\")]\n",
    "# Y_recon = {k: cp2np(d.reconstruct()).squeeze() for k,d in D_recon.items()}\n",
    "# DGf = {k: d.Df * rfftn(d.Y, s=None, axes=(0,1)) for k,d in D_recon.items()}\n",
    "# DG = {k: irfftn(dgf, s=(150,150), axes=(0,1)) for k,dgf in DGf.items()}\n",
    "# G_recon = {k: cp2np(d.getcoef()).squeeze() for k,d in D_recon.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Total Accuracy is %0.4f\" % (np.sum(np.diag(CDLConf)) / np.sum(CDLConf)))\n",
    "print(\"Average Reconstructed SNR %f\" % (np.mean(CDLSNR)))\n",
    "print(np.min(Xtrue))\n",
    "print(np.max(Xtrue))\n",
    "for m in range(X_recon_cpu.shape[-1]):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(np.clip(0.5*Xtrue[...,m] + 0.5, 0, 1))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.clip(X_recon_cpu[...,m],0,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the 10000 test images: %d %%' %\n",
    "      (100.0 * np.sum(np.diag(CDLConf)) / np.sum(CDLConf)))\n",
    "CDLCprob = CDLConf.astype(np.float32) / np.sum(CDLConf, axis=1, keepdims=True).astype(np.float32)\n",
    "cm = metrics.ConfusionMatrixDisplay(CDLCprob, list(testDataset.categories)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.ConfusionMatrixDisplay(CNoiseprob, list(testDataset.categories)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npd = 16\n",
    "fltlmbd = 200.0\n",
    "lmbda = 5.0e-2\n",
    "ropt = cbpdn.ConvBPDN.Options({'Verbose': False,\n",
    "                              'DataType': np.float32,\n",
    "                              'MaxMainIter': 50,\n",
    "                              'HighMemSolve': True,\n",
    "                              'RelStopTol': 1e-7,\n",
    "                              'NonNegCoef': True,\n",
    "                              'FastSolve': True,\n",
    "                              'rho': 1e3,\n",
    "                              'AutoRho': {\"Enabled\": False}})\n",
    "CDLCleanConf = np.zeros((len(testDataset.categories),len(testDataset.categories)), dtype=np.uint)\n",
    "t = tqdm(enumerate(testDataLoader, 0), desc=\"CDL Denoising\", total=len(testNoiseDataLoader))\n",
    "for m,data in t:\n",
    "#     data = iter(testDataLoader).next()\n",
    "    X,y = data\n",
    "    Xl, Xh = util.tikhonov_filter(X.numpy().transpose((2,3,1,0)), fltlmbd, npd)\n",
    "    device = pt.device(\"cuda:0\" if pt.cuda.is_available() else \"cpu\")\n",
    "    X = pt.from_numpy(Xh).to(device, non_blocking=True)\n",
    "    csc = cbpdn.ConvBPDN(D, X, lmbda, ropt)\n",
    "    csc.solve()\n",
    "    Xh_recon = cp2np(csc.reconstruct())\n",
    "    X_recon = pt.from_numpy((Xl + Xh_recon).transpose((3,2,0,1))).to(device, non_blocking=True)\n",
    "    outputs = net(X_recon)\n",
    "    _, predicted = pt.max(outputs, 1)\n",
    "    for i in range(images.shape[0]):\n",
    "        CDLCleanConf[y[i], predicted[i]] += np.uint(1)\n",
    "    \n",
    "    t.set_description(\"Running Accuracy: %f\" % (np.sum(np.diag(CDLConf)) / np.sum(CDLConf)))\n",
    "CDLCleanprob = CDLCleanConf.astype(np.float32) / np.sum(CDLCleanConf, axis=0, keepdims=True).astype(np.float32)\n",
    "\n",
    "cm = metrics.ConfusionMatrixDisplay(CDLCleanConf, list(testDataset.categories)).plot()\n",
    "# [d.solve() for d in tqdm(D_recon.values(), desc=\"Solving Sparse Coding\")]\n",
    "# Y_recon = {k: cp2np(d.reconstruct()).squeeze() for k,d in D_recon.items()}\n",
    "# DGf = {k: d.Df * rfftn(d.Y, s=None, axes=(0,1)) for k,d in D_recon.items()}\n",
    "# DG = {k: irfftn(dgf, s=(150,150), axes=(0,1)) for k,dgf in DGf.items()}\n",
    "# G_recon = {k: cp2np(d.getcoef()).squeeze() for k,d in D_recon.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del csc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
