{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "\n",
    "import noiseprofile\n",
    "import IntelSceneDataset as isds\n",
    "import classifiers\n",
    "from classifiers import SimpleClassifier\n",
    "\n",
    "import denoise\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sporco import util\n",
    "from sporco import linalg\n",
    "from sporco import plot\n",
    "plot.config_notebook_plotting()\n",
    "from sporco.cupy import (cupy_enabled, np2cp, cp2np, select_device_by_load,\n",
    "                         gpu_info)\n",
    "from sporco.cupy.dictlrn import onlinecdl\n",
    "from sporco.cupy.admm import cbpdn\n",
    "from sporco.cupy import cnvrep\n",
    "from sporco.cupy import linalg as cplinalg\n",
    "from sporco.cupy import prox as cpprox\n",
    "from sporco.cupy.linalg import irfftn,rfftn\n",
    "from sporco.cupy.linalg import inner\n",
    "\n",
    "import os\n",
    "\n",
    "outpath = \"./data/out\"\n",
    "inpath = \"./data/in\"\n",
    "confpath = os.path.join(outpath, \"conf\")\n",
    "noisepath = os.path.join(outpath, \"noise\")\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose(\n",
    "    [tv.transforms.CenterCrop(150),\n",
    "     tv.transforms.ToTensor(),\n",
    "     tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = \"/mnt/hd-storage/IntelImageClassification\"\n",
    "\n",
    "\n",
    "\n",
    "cleanTe = isds.IntelSceneDataset(dbpath, segment=\"test\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SimpleClassifier(cleanTe.categories)\n",
    "# clf.load(\"clean_sclf.pt\")\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = torch.nn.Linear(16 * 34 * 34, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # relu preserves dimensions\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv1(x))) # in R^[N, Cout, |X|-|W|+1, |X|-|W|+1]\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, np.prod(x.shape[1:]))\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "clfname = \"Resnet50CNN_NoPP\"\n",
    "    \n",
    "clf = SimpleClassifier(cleanTe.categories, network=torch.load(os.path.join(inpath, f\"{clfname}.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noises = {\n",
    "# #     \"dropred\": noise.ChannelDropoutNoise(0),\n",
    "# #     \"dropgreen\": noise.ChannelDropoutNoise(1),\n",
    "# #     \"dropblue\": noise.ChannelDropoutNoise(2),\n",
    "#     \"awn0\": noise.AdditiveWhiteNoise(0, 0.1),\n",
    "#     \"srn0\": noise.ScalarRayleighNoise(0.8),\n",
    "#     \"drop0\": noise.DropoutNoise(0.05, axis=1),\n",
    "#     \"awn1\": noise.AdditiveWhiteNoise(0, 0.2),\n",
    "#     \"srn1\": noise.ScalarRayleighNoise(0.9),\n",
    "#     \"drop1\": noise.DropoutNoise(0.1, axis=1),\n",
    "#     \"awn2\": noise.AdditiveWhiteNoise(0, 0.3),\n",
    "#     \"srn2\": noise.ScalarRayleighNoise(1.0),\n",
    "#     \"drop2\": noise.DropoutNoise(0.15, axis=1),\n",
    "#     \"awn3\": noise.AdditiveWhiteNoise(0, 0.4),\n",
    "#     \"srn3\": noise.ScalarRayleighNoise(1.1),\n",
    "#     \"drop3\": noise.DropoutNoise(0.2, axis=1),\n",
    "#     \"awn4\": noise.AdditiveWhiteNoise(0, 0.5),\n",
    "#     \"srn4\": noise.ScalarRayleighNoise(1.2),\n",
    "#     \"drop4\": noise.DropoutNoise(0.25, axis=1),\n",
    "#     \"awn5\": noise.AdditiveWhiteNoise(0, 0.6),\n",
    "#     \"srn5\": noise.ScalarRayleighNoise(1.3),\n",
    "#     \"drop5\": noise.DropoutNoise(0.3, axis=1)\n",
    "# }\n",
    "\n",
    "# noisepath = os.path.join(outpath, \"noise\")\n",
    "# noisefnames = {k: os.path.join(noisepath, f\"{k}_error.npz\") for k in noises.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'awn': [{'mean': 0, 'std': 0.1}, {'mean': 0, 'std': 0.2}, {'mean': 0, 'std': 0.3}, {'mean': 0, 'std': 0.4}, {'mean': 0, 'std': 0.5}, {'mean': 0, 'std': 0.6}], 'srn': [{'scale': 0.7}, {'scale': 0.8}, {'scale': 0.9}, {'scale': 1.0}, {'scale': 1.1}, {'scale': 1.2}, {'scale': 1.3}], 'drop': [{'rate': 0.05}, {'rate': 0.1}, {'rate': 0.15}, {'rate': 0.2}, {'rate': 0.25}, {'rate': 0.3}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13adf30b2e624aafae59c62357eb47aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3322af527314d8aa9344c140b1af007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9f056bb38849d39f9c609b2685aead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "Loading...\n",
      "\n",
      "{'awn': [<noiseprofile.AdditiveWhiteNoise object at 0x7fa95b63b090>, <noiseprofile.AdditiveWhiteNoise object at 0x7fa8920e9f90>, <noiseprofile.AdditiveWhiteNoise object at 0x7fa8920d6a10>, <noiseprofile.AdditiveWhiteNoise object at 0x7fa8920f2710>, <noiseprofile.AdditiveWhiteNoise object at 0x7fa8920d6e10>, <noiseprofile.AdditiveWhiteNoise object at 0x7fa89207c750>], 'srn': [<noiseprofile.ScalarRayleighNoise object at 0x7fa8920dd5d0>, <noiseprofile.ScalarRayleighNoise object at 0x7fa89208c090>, <noiseprofile.ScalarRayleighNoise object at 0x7fa8920dd310>, <noiseprofile.ScalarRayleighNoise object at 0x7fa892082090>, <noiseprofile.ScalarRayleighNoise object at 0x7fa89208cb90>, <noiseprofile.ScalarRayleighNoise object at 0x7fa892098dd0>, <noiseprofile.ScalarRayleighNoise object at 0x7fa8920ddf50>], 'drop': [<noiseprofile.DropoutNoise object at 0x7fa89203c150>, <noiseprofile.DropoutNoise object at 0x7fa89203c950>, <noiseprofile.DropoutNoise object at 0x7fa8920a2590>, <noiseprofile.DropoutNoise object at 0x7fa8920a2e90>, <noiseprofile.DropoutNoise object at 0x7fa8920a28d0>, <noiseprofile.DropoutNoise object at 0x7fa8920d6c10>]}\n"
     ]
    }
   ],
   "source": [
    "import noiseprofile\n",
    "std = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "scale = [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]\n",
    "rate = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "noiseparams = {\n",
    "    \"awn\": [{\"mean\": 0, \"std\": s} for s in std],\n",
    "    \"srn\": [{\"scale\": s} for s in scale],\n",
    "    \"drop\": [{\"rate\": r} for r in rate]\n",
    "}\n",
    "print(noiseparams)\n",
    "noises = {k: [None]*len(params) for k,params in noiseparams.items()}\n",
    "\n",
    "for i in tqdm(range(len(noiseparams[\"awn\"]))):\n",
    "    fname = os.path.join(noisepath, f\"Noise_awn{i}.npz\")\n",
    "    if os.path.exists(fname):\n",
    "        print(\"Loading...\")\n",
    "        noises[\"awn\"][i] = noiseprofile.AdditiveWhiteNoise.load(fname)\n",
    "    else:\n",
    "        print(\"Generating...\")\n",
    "        noises[\"awn\"][i] = noiseprofile.AdditiveWhiteNoise(noiseparams[\"awn\"][i])\n",
    "    \n",
    "for i in tqdm(range(len(noiseparams[\"srn\"]))):\n",
    "    fname = os.path.join(noisepath, f\"Noise_srn{i}.npz\")\n",
    "    if os.path.exists(fname):\n",
    "        print(\"Loading...\")\n",
    "        noises[\"srn\"][i] = noiseprofile.ScalarRayleighNoise.load(fname)\n",
    "    else:\n",
    "        print(\"Generating...\")\n",
    "        noises[\"srn\"][i] = noiseprofile.ScalarRayleighNoise(noiseparams[\"srn\"][i])\n",
    "    \n",
    "for i in tqdm(range(len(noiseparams[\"drop\"]))):\n",
    "    fname = os.path.join(noisepath, f\"Noise_drop{i}.npz\")\n",
    "    if os.path.exists(fname):\n",
    "        print(\"Loading...\")\n",
    "        noises[\"drop\"][i] = noiseprofile.DropoutNoise.load(fname)\n",
    "    else:\n",
    "        print(\"Generating...\")\n",
    "        noises[\"drop\"][i] = noiseprofile.DropoutNoise(noiseparams[\"drop\"][i])\n",
    "    \n",
    "print(noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in noises.keys():\n",
    "#     for m in range(len(noises[j])):\n",
    "#         noise = noises[j][m]\n",
    "#         print(noises[j][m].param)\n",
    "#         fname = os.path.join(noisepath, f\"{j}{m}_error\")\n",
    "#         noise.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = noiseprofile.DropoutNoise.load(\"./data/out/noise/drop2_error.npz\")\n",
    "# B = noises[\"drop\"][2]\n",
    "# print(A.param)\n",
    "# print(B.param)\n",
    "# print(type(A.epsilon))\n",
    "# print(type(B.epsilon))\n",
    "# print(B.size)\n",
    "# print(A)\n",
    "# print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose(\n",
    "    [tv.transforms.CenterCrop(150),\n",
    "     tv.transforms.ToTensor(),\n",
    "     tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batchsize = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5f667c071c452eb9f8fb66f1c2e098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dsTe = {\n",
    "    k: [\n",
    "        isds.IntelNoiseSceneDataset(cleanTe, delta)\n",
    "            for delta in tqdm(noises[k], leave=False)\n",
    "    ]\n",
    "        for k in tqdm(noises.keys())\n",
    "}\n",
    "dsTe[\"clean\"] = [cleanTe]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5d9634d58d43e7a57749b9e7abdb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97260fc9b31f4a58af61886e1030d9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb9aaf2fef94480ad8aa9a24dd2d862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a30a3b21f0d406885a67f292871dd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sure noise is saved\n",
    "for ntype in tqdm(noises.keys()):\n",
    "    for nidx in tqdm(range(len(noises[ntype]))):\n",
    "        fname = os.path.join(noisepath, f\"Noise_{ntype}{nidx}.npz\")\n",
    "        if not os.path.exists(fname):\n",
    "            noises[ntype][nidx].save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check that it was saved\n",
    "\n",
    "# for i in range(len(noises[\"awn\"])):\n",
    "#     fname= os.path.join(noisepath, f\"Noise_awn{i}.npz\")\n",
    "#     A = noiseprofile.AdditiveWhiteNoise.load(fname)\n",
    "#     print(np.linalg.norm((A.epsilon - noises[\"awn\"][i].epsilon).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrFlag = {k: True for k in dsTe.keys()}\n",
    "snrFlag[\"clean\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3,\n",
      " 'Cd': 3,\n",
      " 'K': 8,\n",
      " 'M': 240,\n",
      " 'N': 22500,\n",
      " 'Nv': (150, 150),\n",
      " 'axisC': 2,\n",
      " 'axisK': 3,\n",
      " 'axisM': 4,\n",
      " 'axisN': (0, 1),\n",
      " 'dimC': 1,\n",
      " 'dimCd': 1,\n",
      " 'dimK': 1,\n",
      " 'dimN': 2,\n",
      " 'shpD': (10, 10, 3, 1, 240),\n",
      " 'shpS': (150, 150, 3, 8, 1),\n",
      " 'shpX': (150, 150, 1, 8, 240)}\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "batchdims = denoise.CSC.batchdims(cleanTe.shape[2:], cleanTe.shape[1], batchsize)\n",
    "batchkeys = {\"sigshape\", \"channels\", \"batchsize\"}\n",
    "dictfname = \"test_dict.npy\"\n",
    "csc = denoise.CSC(dictfname, batchdims, dimN=2, dtype=torch.float32)\n",
    "print(csc.lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import denoise\n",
    "# dataloader = torch.utils.data.DataLoader(dsTe[\"srn\"],\n",
    "#                                              batch_size=batchsize,\n",
    "#                                              shuffle=True,\n",
    "#                                              pin_memory=True,\n",
    "#                                              num_workers=0)\n",
    "# # print(dsTe[:10,...])\n",
    "# noise_key = \"srn\"\n",
    "# img_clean = dsTe[\"clean\"][0].__getitem__(0)[\"images\"].to(device)\n",
    "# img_noise = dsTe[noise_key][2].__getitem__(0)[\"images\"].to(device)\n",
    "# img_recon = torch.clamp(csc.solve(img_noise.reshape((1,) + img_noise.shape), normed=True, lmbda=1.0e-2)[0,...], -1, 1).squeeze()\n",
    "# print(img_recon.shape)\n",
    "\n",
    "# # noise_diff = torch.abs(img_clean - img_noise)\n",
    "# # recon_diff = torch.abs(img_clean - img_recon)\n",
    "\n",
    "# # print(f\"(min,max) = ({torch.min(img_clean):.3f}, {torch.max(img_clean):.3f})\")\n",
    "# # print(f\"(min,max) = ({torch.min(img_noise):.3f}, {torch.max(img_noise):.3f})\")\n",
    "# # print(f\"(min,max) = ({torch.min(img_recon):.3f}, {torch.max(img_recon):.3f})\")\n",
    "\n",
    "# # imgs = iter(dataloader).next().to(device)[\"images\"]\n",
    "# # rimgs = torch.clamp(csc.normsolve(imgs), -1, 1,)\n",
    "# # dimgs = torch.abs(imgs - rimgs)\n",
    "# # dimgs /= torch.max(dimgs)\n",
    "# # print(f\"(min,max) = ({torch.min(imgs):.3f}, {torch.max(imgs):.3f})\")\n",
    "# # print(f\"(min,max) = ({torch.min(rimgs):.3f}, {torch.max(rimgs):.3f})\")\n",
    "# # print(f\"(min,max) = ({torch.min(dimgs):.3f}, {torch.max(dimgs):.3f})\")\n",
    "# # for m in range(imgs.shape[0]):\n",
    "# #     plt.subplot(2,2,1)\n",
    "# #     plt.imshow(0.5*imgs[m,...].permute((1,2,0)).cpu() + 0.5)\n",
    "# #     plt.subplot(2,2,2)\n",
    "# #     plt.imshow(dimgs[m,...].permute((1,2,0)).cpu())\n",
    "# #     plt.subplot(2,2,3)\n",
    "# #     plt.imshow(0.5*rimgs[m,...].permute((1,2,0)).cpu() + 0.5)\n",
    "# #     plt.subplot(2,2,4)\n",
    "# #     plt.imshow(0.5*torch.abs(rimgs[m,...].permute((1,2,0)).cpu() + 0.5))\n",
    "# #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpuperm = lambda x: x.permute(1,2,0).cpu()\n",
    "# norm = lambda x: 0.5*cpuperm(x) + 0.5\n",
    "# diffnorm = lambda x: cpuperm(x.div_(torch.max(x)))\n",
    "# fig = plt.subplots(2,2, figsize=(10,10))\n",
    "# plt.subplot(2,2,1)\n",
    "# plt.imshow(norm(img_noise))\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.imshow(diffnorm(noise_diff))\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.imshow(norm(img_recon))\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.imshow(diffnorm(recon_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# csc.lmbda = 1.0e-2 # 5.0e-2\n",
    "# for k, data in dsTe.items():\n",
    "#     dataloader = torch.utils.data.DataLoader(data,\n",
    "#                                              batch_size=batchsize,\n",
    "#                                              shuffle=True,\n",
    "#                                              pin_memory=True,\n",
    "#                                              num_workers=0)\n",
    "#     if snrFlag[k]:\n",
    "#         Cnoise[k], SNRnoise[k] = clf.predict(dataloader, calcsnr=snrFlag[k], window=1)\n",
    "#         print(\"No preprocessing:\")\n",
    "#         print(\"%s Accuracy: %.4f\" % (k, np.sum(np.diag(Cnoise[k])) / np.sum(Cnoise[k])))\n",
    "#         print(\"%s Mean SNR: %f dB\" % (k, np.mean(SNRnoise[k])))\n",
    "    \n",
    "#         Ccdl[k], SNRcdl[k] = clf.predict(dataloader, calcsnr=snrFlag[k], window=1, preprocessor=csc.normsolve)\n",
    "#         print(\"Preprocessing with CDL:\")\n",
    "#         print(\"%s Accuracy: %.4f\" % (k, np.sum(np.diag(Ccdl[k])) / np.sum(Ccdl[k])))\n",
    "#         print(\"%s Mean SNR: %f dB\" % (k, np.mean(SNRcdl[k])))\n",
    "#         print(\"============================================================================\")\n",
    "#     else:\n",
    "#         Cnoise[k], _ = clf.predict(dataloader, calcsnr=snrFlag[k], window=1)\n",
    "#         print(\"No preprocessing:\")\n",
    "#         print(\"%s Accuracy: %.4f\" % (k, np.sum(np.diag(Cnoise[k])) / np.sum(Cnoise[k])))\n",
    "    \n",
    "#         Ccdl[k], _ = clf.predict(dataloader, calcsnr=snrFlag[k], window=1, preprocessor=csc.normsolve)\n",
    "#         print(\"Preprocessing with CDL:\")\n",
    "#         print(\"%s Accuracy: %.4f\" % (k, np.sum(np.diag(Ccdl[k])) / np.sum(Ccdl[k])))\n",
    "#         print(\"============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Baseline: Normal$\\left(0, 0.1\\right)$\n",
      "Skipping CDL: Normal$\\left(0, 0.1\\right)$\n",
      "============================================================================\n",
      "Skipping Baseline: Normal$\\left(0, 0.2\\right)$\n",
      "Skipping CDL: Normal$\\left(0, 0.2\\right)$\n",
      "============================================================================\n",
      "Skipping Baseline: Normal$\\left(0, 0.3\\right)$\n",
      "Skipping CDL: Normal$\\left(0, 0.3\\right)$\n",
      "============================================================================\n",
      "Skipping Baseline: Normal$\\left(0, 0.4\\right)$\n",
      "Skipping CDL: Normal$\\left(0, 0.4\\right)$\n",
      "============================================================================\n",
      "Skipping Baseline: Normal$\\left(0, 0.5\\right)$\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[0] (Acc, SNR): (0.0000, 0.000000)', max=375.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "awn 4 Average Accuracy: 0.5067\n",
      "awn 4 Median SNR: 1.7913 dB\n",
      "\n",
      "\n",
      "============================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[0] (Acc, SNR): (0.0000, 0.000000)', max=375.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "awn 5 Average Accuracy: 0.4290\n",
      "awn 5 Median SNR: 1.4235 dB\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[0] (Acc, SNR): (0.0000, 0.000000)', max=375.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "awn 5 Average Accuracy: 0.4567\n",
      "awn 5 Median SNR: 1.4235 dB\n",
      "\n",
      "\n",
      "============================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[0] (Acc, SNR): (0.0000, 0.000000)', max=375.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "srn 0 Average Accuracy: 0.6680\n",
      "srn 0 Median SNR: 3.7555 dB\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6fd0fa05de4281bc7a7b4f28e0a9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[0] (Acc, SNR): (0.0000, 0.000000)', max=375.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IntelSceneDataset\n",
    "import classifiers\n",
    "\n",
    "confopath = os.path.join(outpath, \"conf\")\n",
    "\n",
    "csc.lmbda = 1.0e-2 # 5.0e-2\n",
    "numcats = len(dsTe[\"clean\"][0].categories)\n",
    "numsamps = len(dsTe[\"clean\"][0])\n",
    "A = np.zeros((numcats, numcats))\n",
    "Conf = {\n",
    "    \"Baseline\": {k: [np.zeros((numcats, numcats))]*len(dsTe[k]) for k in dsTe.keys()},\n",
    "    \"CDL\": {k: [np.zeros((numcats, numcats))]*len(dsTe[k]) for k in dsTe.keys()}\n",
    "}\n",
    "SNR = {\n",
    "    \"Baseline\": {k: [np.zeros(numsamps)]*len(dsTe[k]) for k in dsTe.keys()},\n",
    "    \"CDL\": {k: [np.zeros(numsamps)]*len(dsTe[k]) for k in dsTe.keys()}\n",
    "}\n",
    "Pred = {\n",
    "    \"Baseline\": {k: [np.zeros(numsamps)]*len(dsTe[k]) for k in dsTe.keys()},\n",
    "    \"CDL\": {k: [np.zeros(numsamps)]*len(dsTe[k]) for k in dsTe.keys()}\n",
    "}\n",
    "Preprocessor = {\n",
    "    \"Baseline\": None,\n",
    "    \"CDL\": csc.normsolve\n",
    "}\n",
    "for nkey,datalist in dsTe.items():\n",
    "    for nidx in range(len(datalist)):\n",
    "        for pkey,pp in Preprocessor.items():\n",
    "            confname = os.path.join(confopath, f\"{clfname}_Confussion_{pkey}_{nkey}{nidx}.npz\")\n",
    "            errstr = \"None\" if nkey == \"clean\" else str(noises[nkey][nidx])\n",
    "            if os.path.exists(confname):\n",
    "                print(f\"Skipping {pkey}: {errstr}\")\n",
    "                continue\n",
    "            dataloader = torch.utils.data.DataLoader(datalist[nidx],\n",
    "                                                batch_size=batchsize,\n",
    "                                                shuffle=True,\n",
    "                                                pin_memory=True,\n",
    "                                                num_workers=0)\n",
    "            preddct = clf.predict(dataloader, calcsnr=snrFlag[ntype], window=1, preprocessor=pp)\n",
    "            Conf[pkey][nkey][nidx] = preddct[\"Conf\"].copy()\n",
    "            Pred[pkey][nkey][nidx] = preddct[\"labels\"].copy()\n",
    "            print(f\"{nkey} {nidx} Average Accuracy: {np.sum(np.diag(preddct['Conf'])) / np.sum(preddct['Conf']):.4f}\")\n",
    "            if snrFlag[nkey]:\n",
    "                SNR[pkey][nkey][nidx] = preddct[\"SNR\"].copy()\n",
    "                print(f\"{nkey} {nidx} Median SNR: {np.median(SNR[pkey][nkey][nidx]):.4f} dB\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            try:\n",
    "                np.savez_compressed(confname,\n",
    "                                    C=Conf[pkey][nkey][nidx],\n",
    "                                    SNR=SNR[pkey][nkey][nidx],\n",
    "                                    Pred=Pred[pkey][nkey][nidx])\n",
    "            except Exception as e:\n",
    "                print(e.message, e.args)\n",
    "        print(\"============================================================================\")\n",
    "            \n",
    "            \n",
    "            \n",
    "# for k, data in dsTe.items():\n",
    "#     dataloader = torch.utils.data.DataLoader(data,\n",
    "#                                              batch_size=batchsize,\n",
    "#                                              shuffle=True,\n",
    "#                                              pin_memory=True,\n",
    "#                                              num_workers=0)\n",
    "#     if k == \"clean\":\n",
    "#         break\n",
    "#     for j in Conf.keys():\n",
    "#         preddct = clf.predict(dataloader, calcsnr=snrFlag[k], window=1, preprocessor=Preprocessor[j])\n",
    "#         Conf[j][k] = preddct[\"Conf\"]\n",
    "#         Pred[j][k] = preddct[\"labels\"]\n",
    "#         print(f\"{j}:\")\n",
    "#         print(f\"{k} Accuracy: {np.sum(np.diag(Conf[j][k])) / np.sum(Conf[j][k]):.4f}\")\n",
    "#         if snrFlag[k]:\n",
    "#             SNR[j][k] = preddct[\"SNR\"]\n",
    "#             print(f\"{k} Mean SNR: {np.mean(SNR[j][k]):.4f} dB\")\n",
    "#         print(\"\\n\")\n",
    "#         confname = os.path.join(confopath, f\"{clfname}_Confussion_{j}_{k}.npz\")\n",
    "#         try:\n",
    "#             np.savez_compressed(confname, C=Conf[j][k], SNR=SNR[j][k], Pred=Pred[j][k])\n",
    "#         except Exception as e:\n",
    "#             print(e.message, e.args)\n",
    "#     print(\"============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.load(f\"./data/out/conf/{clfname}_Confussion_Baseline_srn6.npz\")\n",
    "print(A['Pred'].shape)\n",
    "print(A['C'].shape)\n",
    "print(A['SNR'].shape)\n",
    "print(dsTe[\"clean\"][0].y.shape)\n",
    "# for k,C in Ccdl.items():\n",
    "#     fname = str(k) + \"_\" + confcdlfname\n",
    "#     try:\n",
    "#         np.savez_compressed(fname, k=C)\n",
    "#     except Exception as e:\n",
    "#         print(e.message, e.args)\n",
    "\n",
    "# confnoisefname = \"ConfusionNoise.npz\"\n",
    "\n",
    "# for k,C in Cnoise.items():\n",
    "#     fname = str(k) + \"_\" + confnoisefname\n",
    "#     try:\n",
    "#         np.savez_compressed(fname, k=C)\n",
    "#     except Exception as e:\n",
    "#         print(e.message, e.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
