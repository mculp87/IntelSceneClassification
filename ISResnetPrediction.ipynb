{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "\n",
    "import noiseprofile as noise\n",
    "import IntelSceneDataset as isds\n",
    "import classifiers\n",
    "from classifiers import SimpleClassifier\n",
    "\n",
    "import denoise\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sporco import util\n",
    "from sporco import linalg\n",
    "from sporco import plot\n",
    "plot.config_notebook_plotting()\n",
    "from sporco.cupy import (cupy_enabled, np2cp, cp2np, select_device_by_load,\n",
    "                         gpu_info)\n",
    "from sporco.cupy.dictlrn import onlinecdl\n",
    "from sporco.cupy.admm import cbpdn\n",
    "from sporco.cupy import cnvrep\n",
    "from sporco.cupy import linalg as cplinalg\n",
    "from sporco.cupy import prox as cpprox\n",
    "from sporco.cupy.linalg import irfftn,rfftn\n",
    "from sporco.cupy.linalg import inner\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose(\n",
    "    [tv.transforms.CenterCrop(150),\n",
    "     tv.transforms.ToTensor(),\n",
    "     tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = \"/mnt/hd-storage/IntelImageClassification\"\n",
    "\n",
    "baseoutdir = \"./data/out\"\n",
    "\n",
    "\n",
    "\n",
    "cleanTe = isds.IntelSceneDataset(dbpath, segment=\"test\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SimpleClassifier(cleanTe.categories)\n",
    "# clf.load(\"clean_sclf.pt\")\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = torch.nn.Linear(16 * 34 * 34, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # relu preserves dimensions\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv1(x))) # in R^[N, Cout, |X|-|W|+1, |X|-|W|+1]\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, np.prod(x.shape[1:]))\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "preprocessing = False\n",
    "clfname = \"Resnet50\"\n",
    "ppstr = \"PP\" if preprocessing else \"NoPP\"\n",
    "clffname = f\"{clfname}_{ppstr}.pt\"\n",
    "clf = SimpleClassifier(cleanTe.categories, network=torch.load(clffname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = {\n",
    "#     \"dropred\": noise.ChannelDropoutNoise(0),\n",
    "#     \"dropgreen\": noise.ChannelDropoutNoise(1),\n",
    "#     \"dropblue\": noise.ChannelDropoutNoise(2),\n",
    "    \"awn0\": noise.AdditiveWhiteNoise(0, 0.1),\n",
    "    \"awn1\": noise.AdditiveWhiteNoise(0, 0.2),\n",
    "    \"awn2\": noise.AdditiveWhiteNoise(0, 0.3),\n",
    "    \"awn3\": noise.AdditiveWhiteNoise(0, 0.4),\n",
    "    \"awn4\": noise.AdditiveWhiteNoise(0, 0.5),\n",
    "    \"awn5\": noise.AdditiveWhiteNoise(0, 0.6),\n",
    "    \"srn0\": noise.ScalarRayleighNoise(0.8*np.sqrt(2.0 / np.pi)),\n",
    "    \"srn1\": noise.ScalarRayleighNoise(0.9*np.sqrt(2.0 / np.pi)),\n",
    "    \"srn2\": noise.ScalarRayleighNoise(1.0*np.sqrt(2.0 / np.pi)),\n",
    "    \"srn3\": noise.ScalarRayleighNoise(1.1*np.sqrt(2.0 / np.pi)),\n",
    "    \"srn4\": noise.ScalarRayleighNoise(1.2*np.sqrt(2.0 / np.pi)),\n",
    "    \"drop0\": noise.DropoutNoise(0.05, axis=1),\n",
    "    \"drop1\": noise.DropoutNoise(0.1, axis=1),\n",
    "    \"drop2\": noise.DropoutNoise(0.15, axis=1),\n",
    "    \"drop3\": noise.DropoutNoise(0.2, axis=1),\n",
    "    \"drop4\": noise.DropoutNoise(0.25, axis=1),\n",
    "    \"drop5\": noise.DropoutNoise(0.3, axis=1)\n",
    "}\n",
    "\n",
    "recalculate = True\n",
    "\n",
    "noisefname = {k: os.path.join(baseoutdir, f\"Noise_{clfname}_{str(k)}.npz\") for k in noises.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose(\n",
    "    [tv.transforms.CenterCrop(150),\n",
    "     tv.transforms.ToTensor(),\n",
    "     tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batchsize = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae4d0d38c24404c8d0da1a535e084a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dsTe = {\"clean\": cleanTe}\n",
    "dsTe.update({\n",
    "    k: isds.IntelNoiseSceneDataset(cleanTe, noises[k], noisefname=(noisefname[k] if not recalculate else None))\n",
    "        for k in tqdm(noises.keys())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558ace475e77402cb6076891166ec9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if recalculate:\n",
    "    for k,fname in tqdm(noisefname.items()):\n",
    "        try:\n",
    "            np.savez(fname, noises[k])\n",
    "        except Exception as e:\n",
    "            print(e.message, e.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3,\n",
      " 'Cd': 3,\n",
      " 'K': 8,\n",
      " 'M': 240,\n",
      " 'N': 22500,\n",
      " 'Nv': (150, 150),\n",
      " 'axisC': 2,\n",
      " 'axisK': 3,\n",
      " 'axisM': 4,\n",
      " 'axisN': (0, 1),\n",
      " 'dimC': 1,\n",
      " 'dimCd': 1,\n",
      " 'dimK': 1,\n",
      " 'dimN': 2,\n",
      " 'shpD': (10, 10, 3, 1, 240),\n",
      " 'shpS': (150, 150, 3, 8, 1),\n",
      " 'shpX': (150, 150, 1, 8, 240)}\n"
     ]
    }
   ],
   "source": [
    "batchdims = denoise.CSC.batchdims(cleanTe.shape[2:], cleanTe.shape[1], batchsize)\n",
    "batchkeys = {\"sigshape\", \"channels\", \"batchsize\"}\n",
    "dictfname = \"test_dict.npy\"\n",
    "csc = denoise.CSC(dictfname, batchdims, dimN=2, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate Confusion matrices\n",
    "preprocessor = {\"Baseline\": None, \"CDL\": csc.normsolve}\n",
    "Conf = {\n",
    "    j: {\n",
    "        k: np.zeros((len(cleanTe.categories), len(cleanTe.categories)), dtype=np.uint)\n",
    "            for k in dsTe.keys()\n",
    "    } for j in preprocessor.keys()\n",
    "}\n",
    "SNR = {j: {k: None for k in dsTe.keys()} for j in preprocessor.keys()}\n",
    "snrFlag = {k: True for k in dsTe.keys()}\n",
    "snrFlag[\"clean\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dsTe[\"srn0\"],\n",
    "                                             batch_size=batchsize,\n",
    "                                             shuffle=True,\n",
    "                                             pin_memory=True,\n",
    "                                             num_workers=0)\n",
    "\n",
    "# noise_key = \"drop0\"\n",
    "# img_clean = dsTe[\"clean\"].__getitem__(0)[\"images\"].to(device)\n",
    "# print(img_clean.shape)\n",
    "# print(dsTe[noise_key].__getitem__(0))\n",
    "# print(dsTe[noise_key].__getitem__(0).keys())\n",
    "# img_noise = dsTe[noise_key].__getitem__(0)[\"images\"].to(device)\n",
    "# img_recon = torch.clamp(csc.solve(img_noise.reshape((1,) + img_noise.shape), normed=True, lmbda=1.0e-2)[0,...], -1, 1).squeeze()\n",
    "\n",
    "# noise_diff = torch.abs(img_clean - img_noise)\n",
    "# recon_diff = torch.abs(img_clean - img_recon)\n",
    "\n",
    "# print(f\"(min,max) = ({torch.min(img_clean):.3f}, {torch.max(img_clean):.3f})\")\n",
    "# print(f\"(min,max) = ({torch.min(img_noise):.3f}, {torch.max(img_noise):.3f})\")\n",
    "# print(f\"(min,max) = ({torch.min(img_recon):.3f}, {torch.max(img_recon):.3f})\")\n",
    "\n",
    "# for m in range(imgs.shape[0]):\n",
    "#     plt.subplot(2,2,1)\n",
    "#     plt.imshow(0.5*imgs[m,...].permute((1,2,0)).cpu() + 0.5)\n",
    "#     plt.subplot(2,2,2)\n",
    "#     plt.imshow(dimgs[m,...].permute((1,2,0)).cpu())\n",
    "#     plt.subplot(2,2,3)\n",
    "#     plt.imshow(0.5*rimgs[m,...].permute((1,2,0)).cpu() + 0.5)\n",
    "#     plt.subplot(2,2,4)\n",
    "#     plt.imshow(0.5*torch.abs(rimgs[m,...].permute((1,2,0)).cpu() + 0.5))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpuperm = lambda x: x.permute(1,2,0).cpu()\n",
    "# norm = lambda x: 0.5*cpuperm(x) + 0.5\n",
    "# diffnorm = lambda x: cpuperm(x.div_(torch.max(x)))\n",
    "# fig = plt.subplots(2,2, figsize=(10,10))\n",
    "# plt.subplot(2,2,1)\n",
    "# plt.imshow(norm(img_noise))\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.imshow(diffnorm(noise_diff))\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.imshow(norm(img_recon))\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.imshow(diffnorm(recon_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab0ff491890448aa33b1f3596d7bec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4913c53da1044a28015e7377fe33fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[0] Accuracy: 0.0000', max=375.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Metrics:\n",
      "clean Accuracy: 0.8527\n",
      "============================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78d98aca9ab4f48b4b72f7d7cdb5eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[0] Accuracy: 0.0000', max=375.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2bc53f40f565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                         \u001b[0mcalcsnr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msnrFlag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                         \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                                         preprocessor=preprocessor[j])\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{j} Metrics:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s Accuracy: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/IntelSceneClassification/classifiers.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, dataloader, calcsnr, window, preprocessor)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mytrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/IntelSceneClassification/denoise.py\u001b[0m in \u001b[0;36mnormsolve\u001b[0;34m(self, S)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnormsolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrsdl_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/IntelSceneClassification/denoise.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, S, out, devopt, normed, lmbda)\u001b[0m\n\u001b[1;32m    571\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelax_AX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/IntelSceneClassification/denoise.py\u001b[0m in \u001b[0;36mxstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m                                     \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxisM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                                     self.cri.axisC)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mirfftn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/IntelSceneClassification/denoise.py\u001b[0m in \u001b[0;36msolvemdbi_ism\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmytake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxisK\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mslcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslcnc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/IntelSceneClassification/denoise.py\u001b[0m in \u001b[0;36mmytake\u001b[0;34m(T, idx, axis)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmytake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msolvemdbi_ism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mah\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxisM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxisK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "csc.lmbda = 1.0e-2 # 5.0e-2\n",
    "for k, data in tqdm(dsTe.items()):\n",
    "    dataloader = torch.utils.data.DataLoader(data,\n",
    "                                             batch_size=batchsize,\n",
    "                                             shuffle=True,\n",
    "                                             pin_memory=True,\n",
    "                                             num_workers=0)\n",
    "    for j in  tqdm(Conf.keys(), leave=False):\n",
    "        if snrFlag[k]:\n",
    "            Conf[j][k], SNR[j][k] = clf.predict(dataloader,\n",
    "                                                calcsnr=snrFlag[k],\n",
    "                                                window=10,\n",
    "                                                preprocessor=preprocessor[j])\n",
    "            print(f\"{j} Metrics:\")\n",
    "            print(\"%s Accuracy: %.4f\" % (k, np.sum(np.diag(Conf[j][k])) / np.sum(Conf[j][k])))\n",
    "            print(\"%s Mean SNR: %f dB\" % (k, np.mean(SNR[j][k])))\n",
    "        else:\n",
    "            Conf[j][k], _ = clf.predict(dataloader,\n",
    "                                        calcsnr=snrFlag[k],\n",
    "                                        window=10,\n",
    "                                        preprocessor=preprocessor[j])\n",
    "            print(f\"{j} Metrics:\")\n",
    "            print(\"%s Accuracy: %.4f\" % (k, np.sum(np.diag(Conf[j][k])) / np.sum(Conf[j][k])))\n",
    "            print(\"============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,Cdct in Conf.keys():\n",
    "    for k,C in Cdct.items():\n",
    "        fname = str(k) + \"_\" + confcdlfname\n",
    "        fname = f\"Confusion_{clfname}_{str(j)}_{str(k)}.npz\"\n",
    "        pname = os.path.join(baseoutdir, fname)\n",
    "        try:\n",
    "            np.savez_compressed(pname, C=C)\n",
    "        except Exception as e:\n",
    "            print(e.message, e.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
